---
title: Prompt Engineering 101
description: Understanding what is Prompt Engineering and how to use it when interacting with Large Language Models (LLMs)
author: Vaibhav Doddihal
tags: #prompt-engineering, #prompt-design, #large-language-models,
created: 2023 May 19
modified: 2023 May 31
---


# Prompt Engineering 101

![img](images/banner_prompt_engineering.jpeg)

## Why do we need Prompt Engineering?
Prompt Engineering is the process of designing prompts that will help large language models (LLMs) perform better at a given task. It is a complex and challenging process, but it can be essential for getting the most out of LLMs.

There are a number of reasons why Prompt Engineering is important. First, LLMs are trained on massive datasets of text and code, but they do not have any understanding of the meaning of that text or code. This means that they can only generate text or code that is consistent with the patterns that they have seen in their training data.

Second, LLMs are very good at generating text or code that is similar to the text or code that they have seen in their training data. However, they are not very good at generating text or code that is creative or original.

Prompt Engineering can help to address both of these challenges. By carefully designing prompts, we can help LLMs to generate text or code that is more meaningful and more creative.

## What is Prompt Engineering?
Prompt Engineering is a process of trial and error. There is no one-size-fits-all approach to Prompt Engineering, and the best approach will vary depending on the task at hand.

However, there are a number of general principles that can be followed when Prompt Engineering. These principles include:

- Be specific. The more specific the prompt, the better the LLM will be able to understand what is being asked of it.
- Use examples. Providing examples can help the LLM to understand the kind of output that is desired.
- Be creative. Don't be afraid to experiment with different prompts and different approaches.
Conclusion

Prompt Engineering is a complex and challenging process, but it can be essential for getting the most out of LLMs. By following the principles outlined above, you can improve your chances of generating high-quality text or code with LLMs.

**Here are some additional tips for Prompt Engineering:**

- Use keywords. When designing a prompt, it is helpful to use keywords that are relevant to the task at hand. This will help the LLM to focus on the relevant information and generate text or code that is more relevant to the task.
- Use natural language. When possible, it is helpful to use natural language when designing a prompt. This will make the prompt easier for the LLM to understand and will help to generate text or code that is more natural and readable.
- Be patient. Prompt Engineering can be a time-consuming process. It may take some trial and error to find the right prompt for a given task. Don't get discouraged if you don't get the results you want right away. Keep experimenting and you will eventually find the right approach.


## So what is the difference between Prompt Design and Prompt Engineering?

| Prompt Design 	| Prompt Engineering 	|
|---	|---	|
| The process of writing prompts that are clear, concise, and easy to understand. 	| The process of optimizing prompts to improve the performance of a language model. 	|
| Focuses on the clarity and conciseness of the prompt. 	| Focuses on the accuracy and efficiency of the generated response. 	|
| Uses a variety of techniques, such as natural language processing, machine learning, and artificial intelligence. 	| Uses a variety of techniques, such as one-shot and few-shot learning, to improve the accuracy and efficiency of the generated response. 	|
| Is a creative and iterative process. 	| Is a data-driven and experimental process. 	|
| Is essential for the success of any language model-based application. 	| Is essential for the continued improvement of language models. 	|


## How to do Prompt Engineering?

Let's go back to our example of writing a poem. While trying to explain different components of the Prompt Design, we have already done some Prompt Engineering. Let's see what we have done so far:

1. We tried to first improve our results by giving more information about the dog. This is what we call as **"Context"**. You can also call it as additional information, background, etc.
2. We tried to make it more specific by giving a name to the dog. This is what we call as **"Persona"**. You can also call it as role, character, etc.
3. We tried to give some instructions to the model by telling it to write a poem. This is what we call as **"Task"**. You can also call it as instructions or commands.

The above process of adding components is also part of the Prompt Engineering process. If we further continue to tweak the prompt to get better results, then that will be part of the Prompt Engineering process.


> Iterative process to improve the results from LLMs by tweaking the prompt is called as Prompt Engineering.

Based on the topic covered so far we now know that Prompt Engineering is a iterative process to 